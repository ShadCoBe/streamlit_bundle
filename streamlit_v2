import os
import sys
import sqlite3
import streamlit as st
import pandas as pd
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go

def save_excel_temp(dataframe, filename):
    filepath = os.path.join(os.getcwd(), filename)
    dataframe.to_excel(filepath, index=False)
    return filepath

def resource_path(*parts):
    base = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))
    return os.path.join(base, *parts)

DB_PATH = resource_path("data", "backend_DQ.db")
LOGO_PATH = resource_path("assets", "cacib.PNG")

# VERSION 2

# --- CONFIGURATION GÉNÉRALE ---
st.set_page_config(page_title="Data Quality & BAM Dashboard", layout="wide")

# --- HEADER ---
col1, col2 = st.columns([1, 5])
with col1:
    st.image(LOGO_PATH, width=150)
with col2:
    st.title("Capital Markets - Data Quality & BAM Dashboard")
    st.caption("Suivi de la qualité des données et de l'activité opérationnelle en temps réel")

st.markdown("---")

# --- SIDEBAR ---
st.sidebar.header("Navigation")
page = st.sidebar.radio("Choisir une vue :", [
    "Vue d'ensemble", "Qualité des données", "Activité & SLA", "Alertes", "À propos"
])

# --- LECTURE BDD ---
with sqlite3.connect(DB_PATH) as conn:
    anomalies_df = pd.read_sql_query("""
    SELECT
        r.control AS Control,
        r.otr_reference AS Anomaly,
        r.criticality AS Criticity,
        r.user_id AS Accountable,
        r.comment as  Action,
        r.due_date AS due_date,
        dates.max_due_date AS update_date,
        r.status AS Status,
        dates.occurence_count,
        dates.duration_days
    FROM REMEDIATIONS r
    JOIN (
        SELECT
            otr_reference,
            control,
            criticality,
            user_id,
            status,
            MIN(due_date) AS min_due_date,
            MAX(due_date) AS max_due_date,
            JULIANDAY(MAX(due_date)) - JULIANDAY(MIN(due_date)) AS duration_days,
            COUNT(*) AS occurence_count
        FROM REMEDIATIONS
        GROUP BY otr_reference, control, criticality, user_id, status
    ) dates
      ON r.otr_reference = dates.otr_reference
     AND r.control = dates.control
     AND r.criticality = dates.criticality
     AND r.user_id = dates.user_id
     AND r.status = dates.status
     AND r.due_date = dates.min_due_date
    """, conn)

anomalies_df = anomalies_df.drop_duplicates()

globnb = 12
nb  = anomalies_df["Control"].str.contains("Settlement Module Completeness", case=False, na=False).sum()
nb1 = anomalies_df["Control"].str.contains("Paco Ack/Nack validation", case=False, na=False).sum()
nb2 = anomalies_df["Control"].str.contains("Trade Version Control", case=False, na=False).sum()
nb3 = anomalies_df["Control"].str.contains("Currency Consistency Check", case=False, na=False).sum()

successr1 = round(globnb/nb, 1)

# --- METRICS MOCK DATA ---
dq_score = 92.5
late_trades = 5
failed_controls = 12
sla_breaches = 3
last_update = datetime.now().strftime("%d/%m/%Y %H:%M")

# --- PAGE : VUE D'ENSEMBLE ---
if page == "Vue d'ensemble":
    st.subheader("Vue d'ensemble des indicateurs clés")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("DQ Global Score", f"{dq_score} %", "+0.5%")
    col2.metric("Trades en retard", late_trades, "-2")
    col3.metric("Contrôles échoués", failed_controls, "+1")
    col4.metric("SLA Breach (24h)", sla_breaches)

    st.info(f"Dernière mise à jour : {last_update}")
    st.markdown("### Commentaires clés :")
    st.markdown("- La qualité des données reste stable mais quelques anomalies détectées sur le booking TEAS.")
    st.markdown("- Les délais de règlement sont maîtrisés, mais vigilance sur les paiements collateral.")

    st.markdown("---")
    st.subheader("Visualisations synthétiques")

    # Graphe 1 : Anomalies par criticité
    dq_anomalies = pd.DataFrame({
        "Criticity": ["Haute", "Moyenne", "Basse"],
        "Nb anomalies": [5, 3, 0]
    })
    fig1 = px.pie(dq_anomalies, names="Criticity", values="Nb anomalies",
                  title="Répartition des anomalies de qualité par criticité")
    st.plotly_chart(fig1, use_container_width=True)

    # Graphe 2 : SLA réel vs cible
    sla_graph = pd.DataFrame({
        "Flux": ["Settlement", "Confirmation", "Reconciliation", "Collateral"],
        "SLA Target": [99, 98, 97, 99],
        "SLA Réel": [98.8, 96.5, 96.2, 99.5]
    })
    fig2 = px.bar(sla_graph, x="Flux", y=["SLA Target", "SLA Réel"],
                  barmode="group", title="Taux de respect des SLA par flux")
    st.plotly_chart(fig2, use_container_width=True)

    # Graphe 3 : Alertes par domaine
    alertes = pd.DataFrame({
        "Domaine": ["Booking TEAS", "Confirmation", "Reconciliation"],
        "Alertes": [2, 1, 1]
    })
    fig3 = px.bar(alertes, x="Domaine", y="Alertes", title="Alertes actives par domaine",
                  color="Domaine", text="Alertes")
    st.plotly_chart(fig3, use_container_width=True)

# --- PAGE : QUALITÉ DES DONNÉES ---
elif page == "Qualité des données":
    st.subheader("Analyse de la qualité des données")

    dq_df = pd.DataFrame({
        "Control": ["Settlement Module Completeness", "Paco Ack/Nack validation", "Trade Version Control", "Currency Consistency Check"],
        "DQ Dimension": ["Exhaustivity, Timeliness", "Exhaustivity, Timeliness", "Completeness", "Consistency, conformity"],
        "Criticity": ["High", "High", "Medium", "Low"],
        "Failure (7d)": [nb, nb1, nb2, nb3],
        "Success Rate": [98.1, 0, 0, 0]
    })

    st.markdown("### Synthèse des contrôles")
    st.dataframe(dq_df, use_container_width=True)

    # Filtrage
    with st.container():
        st.markdown("filtre")

        col1, col2, col3, col4 = st.columns(4)

        # Étape 1 : copie pour filtrer
        filtred_df = anomalies_df.copy()

        with col1:
            control_options = ["All"] + sorted(filtred_df['Control'].dropna().unique().tolist())
            control_filter = st.selectbox("Filtrer par contrôle:", options=control_options)
        if control_filter != "All":
            filtred_df = filtred_df[filtred_df['Control'] == control_filter]

        with col2:
            criticity_options = ["All"] + sorted(filtred_df['Criticity'].dropna().unique().tolist())
            criticite_filter = st.selectbox("Filtrer par criticité:", options=criticity_options)
        if criticite_filter != "All":
            filtred_df = filtred_df[filtred_df['Criticity'] == criticite_filter]

        with col3:
            accountable_options = ["All"] + sorted(filtred_df['Accountable'].dropna().unique().tolist())
            accountable_filter = st.selectbox("Filtrer par responsable:", options=accountable_options)
        if accountable_filter != "All":
            filtred_df = filtred_df[filtred_df['Accountable'] == accountable_filter]

        with col4:
            status_options = ["All"] + sorted(filtred_df['Status'].dropna().unique().tolist())
            status_filter = st.selectbox("Filtrer par status:", options=status_options)
        if status_filter != "All":
            filtred_df = filtred_df[filtred_df['Status'] == status_filter]

        st.markdown(f"**Nombre de lignes filtrées: {len(filtred_df)}**")
        anomalies_df = filtred_df

        if st.button("Créer un mail outlook avec les anomalies"):
            try:
                import win32com.client
                import pythoncom
                import time

                pythoncom.CoInitialize()

                # ✅ connexion à la BDD (et pas au logo)
                with sqlite3.connect(DB_PATH) as conn:
                    cursor = conn.cursor()

                    anomalies_accountable = anomalies_df[anomalies_df["Accountable"] == accountable_filter]

                    if anomalies_accountable.empty:
                        st.warning("Aucune anmalie pour ce responsable.")
                    else:
                        responsible_id = accountable_filter.split("-")[0]
                        cursor.execute(
                            "SELECT email, user_surname FROM USERS WHERE user_id = ?",
                            (responsible_id,)  # ✅ tuple correct
                        )
                        result = cursor.fetchone()
                        if result is None:
                            st.error("Aucun email trouvé pour ce responsable.")
                        else:
                            email = result[0]
                            surname = result[1]
                            file_path = save_excel_temp(anomalies_accountable, f"anomalies_{accountable_filter.replace(' ', '_')}.xlsx")

                            outlook = win32com.client.Dispatch("Outlook.Application")
                            mail = outlook.CreateItem(0)
                            mail.to = email
                            mail.subject = f"[ALERTE] Anomalies détectées - {accountable_filter}"
                            mail.body = mail.HTMLBody = f"""
                                <html>
                                <body>
                                <p>Bonjour {surname}, </p>
                                <p>Des <b style='color:red;'>anomalies critiques</b> ont été détectées dans vos données :</p>
                                <p><b>Nombre d'anomalies : </b> {len(anomalies_accountable)}</p>
                                <p>Vous trouverez en pièce jointe le fichier détaillant ces anomalies.<br>
                                Merci de les traiter <b>dans les plus brefs délais</b> afin de garantir la qualité des données.</p>
                                <p>Data Quality & Monitoring Activity TEAM<br>
                                <p style='color:gray; font-size:10pt;'>--<br>
                                Ce message a été généré automatiquement via l'application de suivi des anomalies.</p>
                                </body>
                                </html>
                            """
                            mail.Attachments.Add(Source=file_path)
                            mail.Display()
                            msg = st.success("mail généré")
                            time.sleep(3)
                            msg.empty()

            except Exception as e:
                st.error(f"une erreur: {e}")

    # Fonctions de coloration
    def color_criticité(val):
        if val == "High":
            return 'background-color: red; color: white'
        elif val == "Medium":
            return 'background-color: orange; color: black'
        elif val == "Low":
            return 'background-color: green; color: white'
        return ''

    def color_statut(val):
        if val == "Ouvert":
            return 'background-color: red; color: white'
        elif val == "En cours":
            return 'background-color: orange; color: black'
        elif val == "Clôturé":
            return 'background-color: green; color: white'
        return ''

    styled_df = anomalies_df.style.map(color_criticité, subset=['Criticity']) \
                                  .map(color_statut, subset=['Status'])

    event = st.dataframe(anomalies_df, on_select="rerun", selection_mode="single-row")

    if event is not None and event.selection is not None:
        selected_rows = event.selection["rows"]
        if selected_rows:
            selected_row_index = selected_rows[0]
            selected_row = anomalies_df.iloc[selected_row_index]

            with st.container():
                st.markdown("""<div style='border:1px solide lightgrey; padding:15px; border-radius:8px; background-color:#f9f9f9'>""", unsafe_allow_html=True)
                st.markdown("### Modifier le statut et ajouter un commentaire")

                col1, col2, col3 = st.columns([1, 3, 1])
                with col1:
                    new_status = st.selectbox(
                        "Statut",
                        ["Ouvert", "En cours", "Clôturé"],
                        index=["Ouvert", "En cours", "Clôturé"].index(selected_row["Status"]),
                        key="statut_choix"
                    )
                with col2:
                    new_comment = st.text_input(
                        "Commentaire:",
                        value=selected_row["Action"],
                        placeholder="EX: Analyse faite par Opérateur",
                        key="comment_choix"
                    )

    if 'selected_row' in locals():
        styled_selected_row = selected_row.to_frame().T.style \
            .map(color_criticité, subset=['Criticity']) \
            .map(color_statut, subset=['Status'])

        st.write(styled_selected_row)

        if st.button("valider les changements", key="valider-btn"):
            if 'selected_row_index' in locals():
                selected_row = anomalies_df.iloc[selected_row_index]
                true_index = selected_row.name

                selected_otr = anomalies_df.at[true_index, 'Anomaly']
                old_status = anomalies_df.at[true_index, "Status"]
                old_comment = anomalies_df.at[true_index, "Action"]

                anomalies_df.at[true_index, "Status"] = new_status
                anomalies_df.at[true_index, "Commentaire"] = new_comment

                try:
                    # ✅ connexion à la BDD (et pas au logo)
                    with sqlite3.connect(DB_PATH) as conn:
                        cursor = conn.cursor()
                        cursor.execute(
                            """ UPDATE REMEDIATIONS
                                SET status = ?, comment = ?
                                WHERE otr_reference = ? """,
                            (new_status, new_comment, selected_otr)
                        )

                        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        user = os.getlogin()
                        cursor.execute(
                            """ INSERT INTO AUDIT_LOGS
                                (timestamp, user, action, table_modified, record_id, field_changed, old_value, new_value, details)
                                VALUES (?,?,?,?,?,?,?,?,?)""",
                            (now, user, "UPDATE", "REMEDIATIONS", selected_otr,
                             "Status/Commentaire", f"{old_status}/{old_comment or ''}",
                             f"{new_status}/{new_comment or ''}", "Modification via Streamlit")
                        )
                        conn.commit()

                    st.success(f"Statut mis à jour: {new_status}")
                    st.write(anomalies_df.loc[[true_index]])
                except Exception as e:
                    st.error(f"erreur lors de la mise à jour dans la base: {e}")
            else:
                st.warning("Veuillez sélectionner une ligne avant de valider")
    else:
        st.info("selectionnez une ligne pour afficher le détail")

# --- PAGE : ACTIVITÉ & SLA ---
elif page == "Activité & SLA":
    st.subheader("📊 BAM Capital Markets – Indicateurs et Workflow")

    import numpy as np

    # --- Données fictives simulées ---
    data = {
        "Date": pd.date_range(start="2025-06-01", periods=10, freq='D'),
        "Desk": ["Rates", "FX", "Credit", "Equity", "Rates", "FX", "Credit", "Equity", "Rates", "FX"],
        "Nb Trades": np.random.randint(80, 200, size=10),
        "SLA %": np.random.uniform(94, 100, size=10),
        "STP %": np.random.uniform(85, 99, size=10),
        "Nb Rejets": np.random.randint(0, 20, size=10),
        "Motif Rejet": ["Missing SSI", "Wrong currency", "No match", "Late Booking", "No match", "Missing SSI", "Wrong currency", "Late Booking", "No match", "Missing SSI"]
    }
    bam_df = pd.DataFrame(data)

    # --- Filtres utilisateurs ---
    desks = bam_df["Desk"].unique()
    selected_desks = st.multiselect("🎯 Choisir un ou plusieurs desks :", desks, default=list(desks))
    filtered_bam = bam_df[bam_df["Desk"].isin(selected_desks)]

    # --- Score Global BAM ---
    bam_score = round((filtered_bam["SLA %"].mean() * 0.7) + (filtered_bam["STP %"].mean() * 0.3), 2)
    col1, col2, col3 = st.columns(3)
    col1.metric("📈 BAM Global Score", f"{bam_score} %")
    col2.metric("✅ SLA moyen", f"{filtered_bam['SLA %'].mean():.2f} %")
    col3.metric("⚙️ STP moyen", f"{filtered_bam['STP %'].mean():.2f} %")

    st.markdown("---")

    # --- Graphiques volumétriques ---
    st.markdown("### 📊 Volumétrie & Performances")
    fig_trades = px.bar(filtered_bam, x="Date", y="Nb Trades", color="Desk", barmode="group", title="Volume de trades par jour")
    st.plotly_chart(fig_trades, use_container_width=True)

    fig_sla = px.line(filtered_bam, x="Date", y="SLA %", color="Desk", markers=True, title="Évolution du SLA %")
    st.plotly_chart(fig_sla, use_container_width=True)

    fig_stp = px.line(filtered_bam, x="Date", y="STP %", color="Desk", markers=True, title="Évolution du STP %")
    st.plotly_chart(fig_stp, use_container_width=True)

    st.markdown("### 🧩 Répartition des rejets STP")
    fig_pie = px.pie(filtered_bam, names="Motif Rejet", values="Nb Rejets", title="Motifs de rejet STP")
    st.plotly_chart(fig_pie, use_container_width=True)

    st.markdown("---")

    # --- Tableau de synthèse avec alertes ---
    def style_sla(val):
        color = "red" if val < 97 else "orange" if val < 99 else "green"
        return f"background-color: {color}; color: white"

    def style_stp(val):
        color = "red" if val < 90 else "orange" if val < 95 else "green"
        return f"background-color: {color}; color: white"

    styled_df = filtered_bam[["Date", "Desk", "Nb Trades", "SLA %", "STP %"]].style \
        .map(style_sla, subset=["SLA %"]) \
        .map(style_stp, subset=["STP %"])

    st.markdown("### 📋 Tableau synthétique (avec alertes de seuils)")
    st.write(styled_df)

    st.markdown("---")

    # --- Workflow BPMN/Processus (type flowchart) ---
    st.subheader("🔀 Sankey Diagram – Flux de traitements Capital Markets")

    # Étapes du processus
    labels = [
        "📘 Booking",        # 0
        "📄 Confirmation",   # 1
        "❌ Rejets Confirmation",  # 2
        "📦 Settlement",     # 3
        "❌ Rejets Settlement",    # 4
        "💰 Payment",        # 5
        "❌ Rejets Payment"  # 6
    ]

    # Flux entre les étapes (source → target)
    sources = [0, 1, 1, 3, 3]
    targets = [1, 3, 2, 5, 4]
    values  = [1000, 950, 50, 910, 40]

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=20, thickness=30, line=dict(color="black", width=1),
            label=labels,
            color=["#6aaed6", "#a1d99b", "#fcbba1", "#9ecae1", "#fdae6b", "#c7e9c0", "#fdd0a2"]
        ),
        link=dict(
            source=sources, target=targets, value=values,
            color=["rgba(100,100,255,0.5)", "rgba(100,255,100,0.5)", "rgba(255,100,100,0.4)",
                   "rgba(255,255,100,0.5)", "rgba(255,150,0,0.4)"]
        )
    )])

    fig.update_layout(title_text="Flux de trades et rejets à chaque étape", font_size=13)
    st.plotly_chart(fig, use_container_width=True)

# --- PAGE : ALERTES ---
elif page == "Alertes":
    st.subheader("Alertes et anomalies actives")

    alerts = [
        {"date": "15/06/2025", "type": "Contrôle échoué", "domaine": "Booking TEAS", "gravité": "Haute"},
        {"date": "15/06/2025", "type": "SLA non respecté", "domaine": "Confirmation", "gravité": "Critique"},
        {"date": "14/06/2025", "type": "Trade en anomalie", "domaine": "Reconciliation", "gravité": "Moyenne"}
    ]
    alert_df = pd.DataFrame(alerts)
    st.table(alert_df)

# --- PAGE : À PROPOS ---
elif page == "À propos":
    st.subheader("À propos de ce dashboard")
    st.markdown("""
    Cette application est conçue pour suivre en temps réel les indicateurs clés de **qualité des données** et de **performance opérationnelle** dans le cadre des activités de marchés (Capital Markets Operations).

    Elle peut être connectée à des outils comme :
    - des référentiels (Markit, Swift, AGS…)
    - des moteurs de contrôles qualité (ex: Talend DQ, Informatica DQ…)
    - des systèmes Middle/Back Office (TEAS, PACO, Settlement...)

    **Contact :** data.teamgovernance@ca-cib.com
    """)

import os
import sys
import sqlite3
import streamlit as st
import pandas as pd
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go

def save_excel_temp(dataframe, filename):
    filepath = os.path.join(os.getcwd(), filename)
    dataframe.to_excel(filepath, index=False)
    return filepath

def resource_path(*parts):
    base = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))
    return os.path.join(base, *parts)

DB_PATH = resource_path("data", "backend_DQ.db")
LOGO_PATH = resource_path("assets", "cacib.PNG")

# VERSION 2

# --- CONFIGURATION G√âN√âRALE ---
st.set_page_config(page_title="Data Quality & BAM Dashboard", layout="wide")

# --- HEADER ---
col1, col2 = st.columns([1, 5])
with col1:
    st.image(LOGO_PATH, width=150)
with col2:
    st.title("Capital Markets - Data Quality & BAM Dashboard")
    st.caption("Suivi de la qualit√© des donn√©es et de l'activit√© op√©rationnelle en temps r√©el")

st.markdown("---")

# --- SIDEBAR ---
st.sidebar.header("Navigation")
page = st.sidebar.radio("Choisir une vue :", [
    "Vue d'ensemble", "Qualit√© des donn√©es", "Activit√© & SLA", "Alertes", "√Ä propos"
])

# --- LECTURE BDD ---
with sqlite3.connect(DB_PATH) as conn:
    anomalies_df = pd.read_sql_query("""
    SELECT
        r.control AS Control,
        r.otr_reference AS Anomaly,
        r.criticality AS Criticity,
        r.user_id AS Accountable,
        r.comment as  Action,
        r.due_date AS due_date,
        dates.max_due_date AS update_date,
        r.status AS Status,
        dates.occurence_count,
        dates.duration_days
    FROM REMEDIATIONS r
    JOIN (
        SELECT
            otr_reference,
            control,
            criticality,
            user_id,
            status,
            MIN(due_date) AS min_due_date,
            MAX(due_date) AS max_due_date,
            JULIANDAY(MAX(due_date)) - JULIANDAY(MIN(due_date)) AS duration_days,
            COUNT(*) AS occurence_count
        FROM REMEDIATIONS
        GROUP BY otr_reference, control, criticality, user_id, status
    ) dates
      ON r.otr_reference = dates.otr_reference
     AND r.control = dates.control
     AND r.criticality = dates.criticality
     AND r.user_id = dates.user_id
     AND r.status = dates.status
     AND r.due_date = dates.min_due_date
    """, conn)

anomalies_df = anomalies_df.drop_duplicates()

globnb = 12
nb  = anomalies_df["Control"].str.contains("Settlement Module Completeness", case=False, na=False).sum()
nb1 = anomalies_df["Control"].str.contains("Paco Ack/Nack validation", case=False, na=False).sum()
nb2 = anomalies_df["Control"].str.contains("Trade Version Control", case=False, na=False).sum()
nb3 = anomalies_df["Control"].str.contains("Currency Consistency Check", case=False, na=False).sum()

successr1 = round(globnb/nb, 1)

# --- METRICS MOCK DATA ---
dq_score = 92.5
late_trades = 5
failed_controls = 12
sla_breaches = 3
last_update = datetime.now().strftime("%d/%m/%Y %H:%M")

# --- PAGE : VUE D'ENSEMBLE ---
if page == "Vue d'ensemble":
    st.subheader("Vue d'ensemble des indicateurs cl√©s")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("DQ Global Score", f"{dq_score} %", "+0.5%")
    col2.metric("Trades en retard", late_trades, "-2")
    col3.metric("Contr√¥les √©chou√©s", failed_controls, "+1")
    col4.metric("SLA Breach (24h)", sla_breaches)

    st.info(f"Derni√®re mise √† jour : {last_update}")
    st.markdown("### Commentaires cl√©s :")
    st.markdown("- La qualit√© des donn√©es reste stable mais quelques anomalies d√©tect√©es sur le booking TEAS.")
    st.markdown("- Les d√©lais de r√®glement sont ma√Ætris√©s, mais vigilance sur les paiements collateral.")

    st.markdown("---")
    st.subheader("Visualisations synth√©tiques")

    # Graphe 1 : Anomalies par criticit√©
    dq_anomalies = pd.DataFrame({
        "Criticity": ["Haute", "Moyenne", "Basse"],
        "Nb anomalies": [5, 3, 0]
    })
    fig1 = px.pie(dq_anomalies, names="Criticity", values="Nb anomalies",
                  title="R√©partition des anomalies de qualit√© par criticit√©")
    st.plotly_chart(fig1, use_container_width=True)

    # Graphe 2 : SLA r√©el vs cible
    sla_graph = pd.DataFrame({
        "Flux": ["Settlement", "Confirmation", "Reconciliation", "Collateral"],
        "SLA Target": [99, 98, 97, 99],
        "SLA R√©el": [98.8, 96.5, 96.2, 99.5]
    })
    fig2 = px.bar(sla_graph, x="Flux", y=["SLA Target", "SLA R√©el"],
                  barmode="group", title="Taux de respect des SLA par flux")
    st.plotly_chart(fig2, use_container_width=True)

    # Graphe 3 : Alertes par domaine
    alertes = pd.DataFrame({
        "Domaine": ["Booking TEAS", "Confirmation", "Reconciliation"],
        "Alertes": [2, 1, 1]
    })
    fig3 = px.bar(alertes, x="Domaine", y="Alertes", title="Alertes actives par domaine",
                  color="Domaine", text="Alertes")
    st.plotly_chart(fig3, use_container_width=True)

# --- PAGE : QUALIT√â DES DONN√âES ---
elif page == "Qualit√© des donn√©es":
    st.subheader("Analyse de la qualit√© des donn√©es")

    dq_df = pd.DataFrame({
        "Control": ["Settlement Module Completeness", "Paco Ack/Nack validation", "Trade Version Control", "Currency Consistency Check"],
        "DQ Dimension": ["Exhaustivity, Timeliness", "Exhaustivity, Timeliness", "Completeness", "Consistency, conformity"],
        "Criticity": ["High", "High", "Medium", "Low"],
        "Failure (7d)": [nb, nb1, nb2, nb3],
        "Success Rate": [98.1, 0, 0, 0]
    })

    st.markdown("### Synth√®se des contr√¥les")
    st.dataframe(dq_df, use_container_width=True)

    # Filtrage
    with st.container():
        st.markdown("filtre")

        col1, col2, col3, col4 = st.columns(4)

        # √âtape 1 : copie pour filtrer
        filtred_df = anomalies_df.copy()

        with col1:
            control_options = ["All"] + sorted(filtred_df['Control'].dropna().unique().tolist())
            control_filter = st.selectbox("Filtrer par contr√¥le:", options=control_options)
        if control_filter != "All":
            filtred_df = filtred_df[filtred_df['Control'] == control_filter]

        with col2:
            criticity_options = ["All"] + sorted(filtred_df['Criticity'].dropna().unique().tolist())
            criticite_filter = st.selectbox("Filtrer par criticit√©:", options=criticity_options)
        if criticite_filter != "All":
            filtred_df = filtred_df[filtred_df['Criticity'] == criticite_filter]

        with col3:
            accountable_options = ["All"] + sorted(filtred_df['Accountable'].dropna().unique().tolist())
            accountable_filter = st.selectbox("Filtrer par responsable:", options=accountable_options)
        if accountable_filter != "All":
            filtred_df = filtred_df[filtred_df['Accountable'] == accountable_filter]

        with col4:
            status_options = ["All"] + sorted(filtred_df['Status'].dropna().unique().tolist())
            status_filter = st.selectbox("Filtrer par status:", options=status_options)
        if status_filter != "All":
            filtred_df = filtred_df[filtred_df['Status'] == status_filter]

        st.markdown(f"**Nombre de lignes filtr√©es: {len(filtred_df)}**")
        anomalies_df = filtred_df

        if st.button("Cr√©er un mail outlook avec les anomalies"):
            try:
                import win32com.client
                import pythoncom
                import time

                pythoncom.CoInitialize()

                # ‚úÖ connexion √† la BDD (et pas au logo)
                with sqlite3.connect(DB_PATH) as conn:
                    cursor = conn.cursor()

                    anomalies_accountable = anomalies_df[anomalies_df["Accountable"] == accountable_filter]

                    if anomalies_accountable.empty:
                        st.warning("Aucune anmalie pour ce responsable.")
                    else:
                        responsible_id = accountable_filter.split("-")[0]
                        cursor.execute(
                            "SELECT email, user_surname FROM USERS WHERE user_id = ?",
                            (responsible_id,)  # ‚úÖ tuple correct
                        )
                        result = cursor.fetchone()
                        if result is None:
                            st.error("Aucun email trouv√© pour ce responsable.")
                        else:
                            email = result[0]
                            surname = result[1]
                            file_path = save_excel_temp(anomalies_accountable, f"anomalies_{accountable_filter.replace(' ', '_')}.xlsx")

                            outlook = win32com.client.Dispatch("Outlook.Application")
                            mail = outlook.CreateItem(0)
                            mail.to = email
                            mail.subject = f"[ALERTE] Anomalies d√©tect√©es - {accountable_filter}"
                            mail.body = mail.HTMLBody = f"""
                                <html>
                                <body>
                                <p>Bonjour {surname}, </p>
                                <p>Des <b style='color:red;'>anomalies critiques</b> ont √©t√© d√©tect√©es dans vos donn√©es :</p>
                                <p><b>Nombre d'anomalies : </b> {len(anomalies_accountable)}</p>
                                <p>Vous trouverez en pi√®ce jointe le fichier d√©taillant ces anomalies.<br>
                                Merci de les traiter <b>dans les plus brefs d√©lais</b> afin de garantir la qualit√© des donn√©es.</p>
                                <p>Data Quality & Monitoring Activity TEAM<br>
                                <p style='color:gray; font-size:10pt;'>--<br>
                                Ce message a √©t√© g√©n√©r√© automatiquement via l'application de suivi des anomalies.</p>
                                </body>
                                </html>
                            """
                            mail.Attachments.Add(Source=file_path)
                            mail.Display()
                            msg = st.success("mail g√©n√©r√©")
                            time.sleep(3)
                            msg.empty()

            except Exception as e:
                st.error(f"une erreur: {e}")

    # Fonctions de coloration
    def color_criticit√©(val):
        if val == "High":
            return 'background-color: red; color: white'
        elif val == "Medium":
            return 'background-color: orange; color: black'
        elif val == "Low":
            return 'background-color: green; color: white'
        return ''

    def color_statut(val):
        if val == "Ouvert":
            return 'background-color: red; color: white'
        elif val == "En cours":
            return 'background-color: orange; color: black'
        elif val == "Cl√¥tur√©":
            return 'background-color: green; color: white'
        return ''

    styled_df = anomalies_df.style.map(color_criticit√©, subset=['Criticity']) \
                                  .map(color_statut, subset=['Status'])

    event = st.dataframe(anomalies_df, on_select="rerun", selection_mode="single-row")

    if event is not None and event.selection is not None:
        selected_rows = event.selection["rows"]
        if selected_rows:
            selected_row_index = selected_rows[0]
            selected_row = anomalies_df.iloc[selected_row_index]

            with st.container():
                st.markdown("""<div style='border:1px solide lightgrey; padding:15px; border-radius:8px; background-color:#f9f9f9'>""", unsafe_allow_html=True)
                st.markdown("### Modifier le statut et ajouter un commentaire")

                col1, col2, col3 = st.columns([1, 3, 1])
                with col1:
                    new_status = st.selectbox(
                        "Statut",
                        ["Ouvert", "En cours", "Cl√¥tur√©"],
                        index=["Ouvert", "En cours", "Cl√¥tur√©"].index(selected_row["Status"]),
                        key="statut_choix"
                    )
                with col2:
                    new_comment = st.text_input(
                        "Commentaire:",
                        value=selected_row["Action"],
                        placeholder="EX: Analyse faite par Op√©rateur",
                        key="comment_choix"
                    )

    if 'selected_row' in locals():
        styled_selected_row = selected_row.to_frame().T.style \
            .map(color_criticit√©, subset=['Criticity']) \
            .map(color_statut, subset=['Status'])

        st.write(styled_selected_row)

        if st.button("valider les changements", key="valider-btn"):
            if 'selected_row_index' in locals():
                selected_row = anomalies_df.iloc[selected_row_index]
                true_index = selected_row.name

                selected_otr = anomalies_df.at[true_index, 'Anomaly']
                old_status = anomalies_df.at[true_index, "Status"]
                old_comment = anomalies_df.at[true_index, "Action"]

                anomalies_df.at[true_index, "Status"] = new_status
                anomalies_df.at[true_index, "Commentaire"] = new_comment

                try:
                    # ‚úÖ connexion √† la BDD (et pas au logo)
                    with sqlite3.connect(DB_PATH) as conn:
                        cursor = conn.cursor()
                        cursor.execute(
                            """ UPDATE REMEDIATIONS
                                SET status = ?, comment = ?
                                WHERE otr_reference = ? """,
                            (new_status, new_comment, selected_otr)
                        )

                        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        user = os.getlogin()
                        cursor.execute(
                            """ INSERT INTO AUDIT_LOGS
                                (timestamp, user, action, table_modified, record_id, field_changed, old_value, new_value, details)
                                VALUES (?,?,?,?,?,?,?,?,?)""",
                            (now, user, "UPDATE", "REMEDIATIONS", selected_otr,
                             "Status/Commentaire", f"{old_status}/{old_comment or ''}",
                             f"{new_status}/{new_comment or ''}", "Modification via Streamlit")
                        )
                        conn.commit()

                    st.success(f"Statut mis √† jour: {new_status}")
                    st.write(anomalies_df.loc[[true_index]])
                except Exception as e:
                    st.error(f"erreur lors de la mise √† jour dans la base: {e}")
            else:
                st.warning("Veuillez s√©lectionner une ligne avant de valider")
    else:
        st.info("selectionnez une ligne pour afficher le d√©tail")

# --- PAGE : ACTIVIT√â & SLA ---
elif page == "Activit√© & SLA":
    st.subheader("üìä BAM Capital Markets ‚Äì Indicateurs et Workflow")

    import numpy as np

    # --- Donn√©es fictives simul√©es ---
    data = {
        "Date": pd.date_range(start="2025-06-01", periods=10, freq='D'),
        "Desk": ["Rates", "FX", "Credit", "Equity", "Rates", "FX", "Credit", "Equity", "Rates", "FX"],
        "Nb Trades": np.random.randint(80, 200, size=10),
        "SLA %": np.random.uniform(94, 100, size=10),
        "STP %": np.random.uniform(85, 99, size=10),
        "Nb Rejets": np.random.randint(0, 20, size=10),
        "Motif Rejet": ["Missing SSI", "Wrong currency", "No match", "Late Booking", "No match", "Missing SSI", "Wrong currency", "Late Booking", "No match", "Missing SSI"]
    }
    bam_df = pd.DataFrame(data)

    # --- Filtres utilisateurs ---
    desks = bam_df["Desk"].unique()
    selected_desks = st.multiselect("üéØ Choisir un ou plusieurs desks :", desks, default=list(desks))
    filtered_bam = bam_df[bam_df["Desk"].isin(selected_desks)]

    # --- Score Global BAM ---
    bam_score = round((filtered_bam["SLA %"].mean() * 0.7) + (filtered_bam["STP %"].mean() * 0.3), 2)
    col1, col2, col3 = st.columns(3)
    col1.metric("üìà BAM Global Score", f"{bam_score} %")
    col2.metric("‚úÖ SLA moyen", f"{filtered_bam['SLA %'].mean():.2f} %")
    col3.metric("‚öôÔ∏è STP moyen", f"{filtered_bam['STP %'].mean():.2f} %")

    st.markdown("---")

    # --- Graphiques volum√©triques ---
    st.markdown("### üìä Volum√©trie & Performances")
    fig_trades = px.bar(filtered_bam, x="Date", y="Nb Trades", color="Desk", barmode="group", title="Volume de trades par jour")
    st.plotly_chart(fig_trades, use_container_width=True)

    fig_sla = px.line(filtered_bam, x="Date", y="SLA %", color="Desk", markers=True, title="√âvolution du SLA %")
    st.plotly_chart(fig_sla, use_container_width=True)

    fig_stp = px.line(filtered_bam, x="Date", y="STP %", color="Desk", markers=True, title="√âvolution du STP %")
    st.plotly_chart(fig_stp, use_container_width=True)

    st.markdown("### üß© R√©partition des rejets STP")
    fig_pie = px.pie(filtered_bam, names="Motif Rejet", values="Nb Rejets", title="Motifs de rejet STP")
    st.plotly_chart(fig_pie, use_container_width=True)

    st.markdown("---")

    # --- Tableau de synth√®se avec alertes ---
    def style_sla(val):
        color = "red" if val < 97 else "orange" if val < 99 else "green"
        return f"background-color: {color}; color: white"

    def style_stp(val):
        color = "red" if val < 90 else "orange" if val < 95 else "green"
        return f"background-color: {color}; color: white"

    styled_df = filtered_bam[["Date", "Desk", "Nb Trades", "SLA %", "STP %"]].style \
        .map(style_sla, subset=["SLA %"]) \
        .map(style_stp, subset=["STP %"])

    st.markdown("### üìã Tableau synth√©tique (avec alertes de seuils)")
    st.write(styled_df)

    st.markdown("---")

    # --- Workflow BPMN/Processus (type flowchart) ---
    st.subheader("üîÄ Sankey Diagram ‚Äì Flux de traitements Capital Markets")

    # √âtapes du processus
    labels = [
        "üìò Booking",        # 0
        "üìÑ Confirmation",   # 1
        "‚ùå Rejets Confirmation",  # 2
        "üì¶ Settlement",     # 3
        "‚ùå Rejets Settlement",    # 4
        "üí∞ Payment",        # 5
        "‚ùå Rejets Payment"  # 6
    ]

    # Flux entre les √©tapes (source ‚Üí target)
    sources = [0, 1, 1, 3, 3]
    targets = [1, 3, 2, 5, 4]
    values  = [1000, 950, 50, 910, 40]

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=20, thickness=30, line=dict(color="black", width=1),
            label=labels,
            color=["#6aaed6", "#a1d99b", "#fcbba1", "#9ecae1", "#fdae6b", "#c7e9c0", "#fdd0a2"]
        ),
        link=dict(
            source=sources, target=targets, value=values,
            color=["rgba(100,100,255,0.5)", "rgba(100,255,100,0.5)", "rgba(255,100,100,0.4)",
                   "rgba(255,255,100,0.5)", "rgba(255,150,0,0.4)"]
        )
    )])

    fig.update_layout(title_text="Flux de trades et rejets √† chaque √©tape", font_size=13)
    st.plotly_chart(fig, use_container_width=True)

# --- PAGE : ALERTES ---
elif page == "Alertes":
    st.subheader("Alertes et anomalies actives")

    alerts = [
        {"date": "15/06/2025", "type": "Contr√¥le √©chou√©", "domaine": "Booking TEAS", "gravit√©": "Haute"},
        {"date": "15/06/2025", "type": "SLA non respect√©", "domaine": "Confirmation", "gravit√©": "Critique"},
        {"date": "14/06/2025", "type": "Trade en anomalie", "domaine": "Reconciliation", "gravit√©": "Moyenne"}
    ]
    alert_df = pd.DataFrame(alerts)
    st.table(alert_df)

# --- PAGE : √Ä PROPOS ---
elif page == "√Ä propos":
    st.subheader("√Ä propos de ce dashboard")
    st.markdown("""
    Cette application est con√ßue pour suivre en temps r√©el les indicateurs cl√©s de **qualit√© des donn√©es** et de **performance op√©rationnelle** dans le cadre des activit√©s de march√©s (Capital Markets Operations).

    Elle peut √™tre connect√©e √† des outils comme :
    - des r√©f√©rentiels (Markit, Swift, AGS‚Ä¶)
    - des moteurs de contr√¥les qualit√© (ex: Talend DQ, Informatica DQ‚Ä¶)
    - des syst√®mes Middle/Back Office (TEAS, PACO, Settlement...)

    **Contact :** data.teamgovernance@ca-cib.com
    """)
